# MIXFound

**MIXFound** provides a complete pipeline for **fundus image classification** based on several powerful visual backbones (**VisionFM**, **RETFound**, **FLAIR**, **CLIP**) and a novel multi-model fusion strategy.

---

## ðŸ“‘ Table of Contents

- [Features](#-features)
- [Repository Structure](#-repository-structure)
- [Environment Setup](#-environment-setup)
- [Data Preparation](#-data-preparation)
- [Usage](#-usage)
  - [1. Feature Extraction](#1-feature-extraction)
  - [2. Train Classification Decoders](#2-train-classification-decoders)
  - [3. Multi-Model Fusion (MIXFound)](#3-multi-model-fusion-mixfound)
- [Evaluation & Outputs](#-evaluation--outputs)
- [Citation](#-citation)
- [License](#-license)

---

## âœ¨ Features

- **ðŸ§© Multiple Backbones Supported**
  - **VisionFM** (Fundus-specific foundation model)
  - **RETFound**
  - **FLAIR**
  - **OpenAI CLIP** (ViT-L/14)

- **ðŸŽ› Flexible Classification Decoders**
  - Linear heads (`ClsHead`) on frozen features.
  - Full support for multi-class classification tasks.

- **ðŸ“ˆ Rich Evaluation Metrics**
  - Accuracy, Precision, Recall, F1-Score.
  - Class-wise and Macro **ROC-AUC**.
  - **Bootstrap 95% CI** for AUC.
  - Confusion matrices and per-class sensitivity/specificity.

- **ðŸš€ Multi-Model Fusion (MIXFound)**
  - Adaptive AUC-based weighting across multiple backbones.
  - Automated generation of ROC comparison plots.

- **âš¡ Reproducible & Scalable**
  - Configurable via `argparse` (Tasks Aâ€“G, seeds, etc.).
  - Distributed Data Parallel (DDP) support.

---

## ðŸ“‚ Repository Structure

```text
Github/
â”œâ”€â”€ environment.yml                # Conda environment specification
â”œâ”€â”€ MIXFound.py                    # ðŸš€ Main Script: Multi-model fusion
â”œâ”€â”€ utils.py                       # Shared utilities (DDP, metrics, logging)
â”œâ”€â”€ dataset/                       # Dataset utilities / wrappers
â”‚
â”œâ”€â”€ Classification/                # ðŸ§  Linear Probing / Decoders
â”‚   â”œâ”€â”€ CLIP_based_classifier.py
â”‚   â”œâ”€â”€ FLAIR_based_classifier.py
â”‚   â”œâ”€â”€ RETFound_based_classifier.py
â”‚   â”œâ”€â”€ VisionFM_based_classifier.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ evaluation_funcs.py
â”‚
â””â”€â”€ Feature_Extraction/            # ðŸ“¸ Feature Extractors
    â”œâ”€â”€ RETFound/
    â”‚   â”œâ”€â”€ RETFound_Feature_Extractor.py
    â”‚   â””â”€â”€ models_vit.py
    â”œâ”€â”€ FLAIR/
    â”‚   â””â”€â”€ FLAIR_Feature_Extractor.py
    â””â”€â”€ ...
---

## âš™ï¸ Environment Setup
# 1. Create environment from provided file
conda env create -f environment.yml -n visionfm

# 2. Activate environment
conda activate visionfm

# 3. (Optional) Export requirements
pip freeze > requirements.txt

## ðŸ’¾ Data Preparation

dataset/
â””â”€â”€ fundus/
    â”œâ”€â”€ A/.../G/                   # Task Splits (e.g., Task A, Task E)
    â”‚   â”œâ”€â”€ AMD/                   # Class folder (Disease Name)
    â”‚   â”œâ”€â”€ Glaucoma/              # Class folder
    â”‚   â”œâ”€â”€ High myopia/           # Class folder
    â”‚   â””â”€â”€ Normal fundus/         # Class folder
    â”‚
    â”œâ”€â”€ training/
    â”‚   â””â”€â”€ training_labels.txt    # Format: path;label
    â”‚   â””â”€â”€ test_labels/           # Validation/Test images
    â””â”€â”€ evaluation/
        â””â”€â”€ evaluation_labels.txt  # Format: path;label
## ðŸš€ Usage

# 1. Feature Extraction

Extract features to .pickle files before training classifiers.

# RETFound Example:
python Feature_Extraction/RETFound/RETFound_Feature_Extractor.py \
    --data_path ./dataset/fundus \
    --Task E \
    --output_dir ./Final_feature

